{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7d9ae2",
   "metadata": {},
   "source": [
    "# This example notebook, uses the provided OGIP files, to plot the Spectral Energy Distribution and Differential Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d550e",
   "metadata": {},
   "source": [
    "One can follow the tutorial from gammapy here https://docs.gammapy.org/0.18.2/tutorials/spectrum_analysis.html\n",
    "\n",
    "# This notebook follows the following steps:\n",
    "## 1. Get the dataset from OGIP files\n",
    "## 2. Get the reference energy for a Log Parabola model Fit\n",
    "## 3. Perform Modeling and Fitting and check some statistics\n",
    "## 4. Plot the various plots\n",
    "## 5. Save Flux Points Dataset and Models to separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.time import Time\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "\n",
    "from gammapy.maps import MapAxis\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling.models import (\n",
    "    Models,\n",
    "    PowerLawSpectralModel,\n",
    "    LogParabolaSpectralModel,\n",
    "    create_crab_spectral_model,\n",
    "    SkyModel,\n",
    ")\n",
    "from gammapy.datasets import Datasets, SpectrumDataset, SpectrumDatasetOnOff, FluxPointsDataset\n",
    "\n",
    "from gammapy.estimators import FluxPointsEstimator, FluxPoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99ae67a",
   "metadata": {},
   "source": [
    "# 1. Get the OGIP files and make some selections if need be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=\"../data/\"\n",
    "dir_path=\"DL3/Crab_src_indep/\" # DL3/BLLac_src_dep\n",
    "\n",
    "ogip_path=Path(base_dir+dir_path+\"OGIP/\")\n",
    "plot_path=Path(base_dir+dir_path+\"plots/\") # Optional directory to store plots\n",
    "\n",
    "# Create the Paths if they do not exist already\n",
    "ogip_path.mkdir(exist_ok=True)\n",
    "plot_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f71054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the full standard_dataset as provided\n",
    "use_standard_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all obs ids of the pha files in the given directory\n",
    "if use_standard_data:\n",
    "    obs_ids = [2967, 2968, 2969, 2970, 2971, 2972, 2973, 2974, 2975, 2976, 2977] # For Crab\n",
    "    # [5552, 5553, 5554, 5555, 5556, 5557, 5558, 5559] # for BL Lac\n",
    "else:\n",
    "    # Get all the OGIP files in the provided location\n",
    "    obs_ids = []\n",
    "    pha_files = list(ogip_path.glob(\"pha_obs*.fits\"))\n",
    "    \n",
    "    for p in pha_files:\n",
    "        run = int(p.name[7:-5])\n",
    "        obs_ids.append(run)\n",
    "    obs_ids = np.sort(np.array(obs_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33e77a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate the Datasets object back from the OGIP files\n",
    "datasets = Datasets()\n",
    "for obs in obs_ids:\n",
    "    file = ogip_path / f\"pha_obs{obs}.fits\"\n",
    "    datasets.append(SpectrumDatasetOnOff.from_ogip_files(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d07c064",
   "metadata": {},
   "source": [
    "# 2. Get some parameters to use from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f07c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_name = []\n",
    "\n",
    "for obs in obs_ids:\n",
    "    file = ogip_path / f\"pha_obs{obs}.fits\"\n",
    "    r = Table.read(file, hdu=\"REGION\").meta\n",
    "    \n",
    "    obj_name.append(r[\"OBJECT\"])\n",
    "print(obs_ids)\n",
    "\n",
    "obj_name = np.unique(np.array(obj_name))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ccd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_reco_edges = datasets[0].counts.geom.axes[\"energy\"].edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef84ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy range for spectral fitting the dataset.\n",
    "# One can play with different energy bins to check the different spectral fits\n",
    "e_fit_min = 0.01 * u.TeV\n",
    "e_fit_max = 40 * u.TeV\n",
    "\n",
    "# Using bins per decade\n",
    "e_fit_bin_p_dec = 5\n",
    "\n",
    "# Calculating the bin size in log scale for the given number of bins per decade\n",
    "e_fit_bin = int(round((np.log10(e_fit_max.value) - np.log10(e_fit_min.value)) * e_fit_bin_p_dec + 1, 0))\n",
    "\n",
    "energy_fit_edges = np.logspace(np.log10(e_fit_min.value), np.log10(e_fit_max.value), e_fit_bin) * u.TeV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910069e1",
   "metadata": {},
   "source": [
    "# 3. Get Pivot energy to fix the reference energy and define the Spectrum Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pivot (decorrelation) energy for a Power Law model to get the reference energy for Log Parabola model\n",
    "def get_pivot_energy(datasets, e_ref, e_edges, obj_name):\n",
    "    \"\"\"\n",
    "    Using Power Law spectral model with the given reference energy and \n",
    "    get the decorrelation energy of the fit, within the fit energy range, e_edges\n",
    "    \"\"\"\n",
    "    spectral_model = PowerLawSpectralModel(\n",
    "        index=2, amplitude=2e-11 * u.Unit(\"cm-2 s-1 TeV-1\"), reference=e_ref\n",
    "    )\n",
    "    model = SkyModel(spectral_model=spectral_model, name=obj_name)\n",
    "    model_check = model.copy()\n",
    "\n",
    "    # Stacked dataset method\n",
    "    stacked_dataset = Datasets(datasets).stack_reduce()\n",
    "    stacked_dataset.models = model_check\n",
    "\n",
    "    fit_stacked = Fit(stacked_dataset)\n",
    "    result_stacked = fit_stacked.run()\n",
    "\n",
    "    return model_check.spectral_model.pivot_energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ref = get_pivot_energy(datasets, 0.4 * u.TeV, e_reco_edges, obj_name)\n",
    "print(ref.to_value(u.GeV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final spectral model of Log Parabola, to be used for estimating the LC.\n",
    "# One can try different Spectral Models as well.\n",
    "# Be careful in the choice of Spectral Model being used for the 2 examples presented here\n",
    "\n",
    "# Crab\n",
    "spectral_model_lp = LogParabolaSpectralModel(\n",
    "        amplitude = 5e-12 * u.Unit('cm-2 s-1 TeV-1'),\n",
    "        reference = ref,\n",
    "        alpha = 2 * u.Unit(''),\n",
    "        beta = 0.1 * u.Unit('')\n",
    ")\n",
    "model_lp = SkyModel(spectral_model=spectral_model_lp, name=obj_name)\n",
    "\n",
    "#BL Lac\n",
    "spectral_model_lp_bllac = LogParabolaSpectralModel(\n",
    "        amplitude = 3e-8 * u.Unit('cm-2 s-1 TeV-1'),\n",
    "        reference = 0.1 * u.TeV,\n",
    "        alpha = 2 * u.Unit(''),\n",
    "        beta = 0.2 * u.Unit('')\n",
    ")\n",
    "model_lp_bllac = SkyModel(spectral_model=spectral_model_lp_bllac, name=obj_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the appropriate models, as per the selection of the source/dataset\n",
    "params=model_lp.to_dict()['spectral']['parameters']\n",
    "# params=model_lp_bllac.to_dict()['spectral']['parameters']\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f61c2c",
   "metadata": {},
   "source": [
    "# 4. Spectral Fitting\n",
    "One can check for a more comprehensive tutorial on Modelling and Fitting, here is the gammapy tutorial https://docs.gammapy.org/0.18.2/tutorials/modeling.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa1a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Using stacked analysis method, where we stack together all Datasets into 1 Dataset and add the model afterwards\n",
    "stacked_dataset = Datasets(datasets).stack_reduce()\n",
    "stacked_dataset.models = model_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006acdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fitting the model to the dataset\n",
    "fit = Fit([stacked_dataset])\n",
    "result = fit.run()\n",
    "model_best = model_lp.copy() # creating a copy of the model, to avoid overwriting of the original object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compute the Flux Points after Fitting the model\n",
    "# We do not do too many optimizations here. \n",
    "# If one wants, can try and check the various attributes of the Estimator\n",
    "fpe = FluxPointsEstimator(\n",
    "    energy_edges=energy_fit_edges, \n",
    "    reoptimize = False\n",
    ")\n",
    "flux_points = fpe.run(datasets=stacked_dataset)\n",
    "    \n",
    "# Define the flux points with just upper limits with a threshold on TS value\n",
    "flux_points.table[\"is_ul\"] = flux_points.table[\"ts\"] < 4\n",
    "\n",
    "flux_points_dataset = FluxPointsDataset(\n",
    "    data=flux_points, models=model_best\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdce50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810aa480",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.to_dict()['spectral']['parameters']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a158e5a7",
   "metadata": {},
   "source": [
    "# 5. Check some features of the Flux points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0da937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Flux table\n",
    "flux_points.table_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51652dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Statistic array\n",
    "print(flux_points_dataset.stat_array())\n",
    "\n",
    "# Total statistics sum\n",
    "print(flux_points_dataset.stat_sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.parameters.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f55fc7",
   "metadata": {},
   "source": [
    "# 6. Spectral plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if obj_name == 'Crab':\n",
    "    ref_label=\"MAGIC LP (JHEAp 2015)\"\n",
    "else:\n",
    "    ref_label=\"Crab MAGIC LP (JHEAp 2015)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c002cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Setting plot axes limits and other args\n",
    "e_plot_min = 0.01 * u.TeV\n",
    "e_plot_max = 50 * u.TeV\n",
    "\n",
    "flux_plot_min = 7e-12\n",
    "flux_plot_max = 2e-10\n",
    "\n",
    "plot_kwargs = {\n",
    "    \"energy_range\": [e_plot_min, e_plot_max],\n",
    "    \"energy_power\": 2,\n",
    "    \"flux_unit\": \"erg-1 cm-2 s-1\",\n",
    "}\n",
    "plot_en_kwargs = {\"energy_range\": [e_plot_min, e_plot_max]}\n",
    "plot_ts_kwargs = {\n",
    "    \"energy_power\": 2,\n",
    "    \"flux_unit\": \"erg-1 cm-2 s-1\",\n",
    "    \"color\": \"darkorange\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS profile plot\n",
    "\n",
    "# Replace values of norm_scan from all nans to be the same as ones without it\n",
    "for i in np.arange(len(flux_points.table)):\n",
    "    if np.isnan(flux_points.table[\"norm_scan\"][i]).all():\n",
    "        flux_points.table[\"norm_scan\"][i] = flux_points.table[\n",
    "            np.where(flux_points.table[\"success\"] == True)[0]\n",
    "        ][\"norm_scan\"][0]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = flux_points.plot(**plot_ts_kwargs)\n",
    "\n",
    "flux_points.to_sed_type(\"e2dnde\").plot_ts_profiles(ax=ax)\n",
    "plt.grid(which='both')\n",
    "plt.title('TS Profiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc63a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model covariance matrix plot\n",
    "model_best.covariance.plot_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7af0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_sed = plt.figure(figsize=(8,8))\n",
    "\n",
    "gs2 = GridSpec(7, 1)\n",
    "\n",
    "gs2.update(hspace=0.1)\n",
    "args1 = [gs2[:5,:]]\n",
    "args2 = [gs2[5:,:]]\n",
    "\n",
    "fig_gs1 = fig_sed.add_subplot(*args1)\n",
    "fig_gs2 = fig_sed.add_subplot(*args2)\n",
    "\n",
    "FluxPointsDataset(data=flux_points, models=model_best).plot_spectrum(ax=fig_gs1, label=\"LST-1 data\")\n",
    "\n",
    "create_crab_spectral_model(\"magic_lp\").plot(\n",
    "    ax=fig_gs1, **plot_kwargs, label=ref_label\n",
    ")\n",
    "\n",
    "fig_gs1.legend()\n",
    "fig_gs1.set_xlim(e_plot_min.value, e_plot_max.value)\n",
    "#fig_gs1.set_ylim(5e-12, 5e-10)\n",
    "fig_gs1.tick_params(labelbottom=False)\n",
    "\n",
    "fig_gs1.grid(which='both')\n",
    "fig_gs1.set_title('SED')\n",
    "\n",
    "flux_points_dataset.plot_residuals(ax=fig_gs2, method='diff/model')\n",
    "fig_gs2.grid(which='both')\n",
    "fig_gs2.set_xlim(e_plot_min.value, e_plot_max.value)\n",
    "fig_gs2.set_ylim(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b48054",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,7))\n",
    "gs = GridSpec(7, 1)\n",
    "\n",
    "args1 = [gs[:5,:]]\n",
    "args2 = [gs[5:,:]]\n",
    "kwargs_res = {\"method\": \"diff\", \"region\": stacked_dataset.counts.geom.region}\n",
    "\n",
    "fig_gs1 = fig.add_subplot(*args1)\n",
    "fig_gs2 = fig.add_subplot(*args2)\n",
    "\n",
    "stacked_dataset.plot_excess(fig_gs1)\n",
    "fig_gs1.grid(which=\"both\")\n",
    "fig_gs1.set_ylabel(\"Excess\")\n",
    "\n",
    "stacked_dataset.plot_residuals_spectral(fig_gs2, **kwargs_res)\n",
    "fig_gs2.grid(which=\"both\")\n",
    "\n",
    "fig_gs2.set_ylabel(f\"Residuals\\n data-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57465e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "flux_points.plot(label='Joint flux')\n",
    "create_crab_spectral_model(\"magic_lp\").plot(**plot_en_kwargs, label=ref_label)\n",
    "plt.grid(which='both')\n",
    "plt.legend()\n",
    "plt.title('Differential spectrum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03c47c",
   "metadata": {},
   "source": [
    "# 7. Save the Flux Points Dataset and Model to separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_points.write(\n",
    "    base_dir + dir_path + f'{obj_name}_dataset_{datasets[0].name}_to_{datasets[-1].name}_flux_pts.fits', \n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# write the model to a dict and then to a file\n",
    "model_dict = model_best.to_dict(full_output='True')\n",
    "\n",
    "f = open(base_dir + dir_path + f'{obj_name}_dataset_{datasets[0].name}_to_{datasets[-1].name}_flux_model_dict.dat', 'wb')\n",
    "\n",
    "pickle.dump(model_dict, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lst-dev",
   "language": "python",
   "name": "lst-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
