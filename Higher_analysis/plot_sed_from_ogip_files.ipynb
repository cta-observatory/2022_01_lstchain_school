{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7d9ae2",
   "metadata": {},
   "source": [
    "# This example notebook, uses the provided OGIP files, to plot the Spectral Energy Distribution and Differential Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d550e",
   "metadata": {},
   "source": [
    "One can follow the tutorial from gammapy here https://docs.gammapy.org/0.19/tutorials/analysis/1D/spectral_analysis.html\n",
    "\n",
    "# This notebook follows the following steps:\n",
    "## 1. Get the dataset from OGIP files\n",
    "## 2. Get the reference energy for a Log Parabola model Fit\n",
    "## 3. Perform Modeling and Fitting and check some statistics\n",
    "## 4. Plot the various plots\n",
    "## 5. Save Flux Points Dataset and Models to separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.time import Time\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "\n",
    "from gammapy.maps import MapAxis\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling.models import (\n",
    "    Models,\n",
    "    PowerLawSpectralModel,\n",
    "    LogParabolaSpectralModel,\n",
    "    create_crab_spectral_model,\n",
    "    SkyModel,\n",
    ")\n",
    "from gammapy.datasets import Datasets, SpectrumDataset, SpectrumDatasetOnOff, FluxPointsDataset\n",
    "\n",
    "from gammapy.estimators import FluxPointsEstimator, FluxPoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99ae67a",
   "metadata": {},
   "source": [
    "# 1. Get the OGIP files and make some selections if need be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../data/\"\n",
    "dir_path = \"DL3/Crab_src_indep/\" # DL3/BLLac_src_dep\n",
    "\n",
    "ogip_path = Path(base_dir+dir_path+\"OGIP/\")\n",
    "\n",
    "# Create the Paths if they do not exist already\n",
    "ogip_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all obs ids of the pha files in the given directory\n",
    "obs_ids = []\n",
    "pha_files = list(ogip_path.glob(\"obs_*_arf.fits.gz\"))\n",
    "    \n",
    "for p in pha_files:\n",
    "    run = int(p.name[4:8])\n",
    "    obs_ids.append(run)\n",
    "obs_ids = np.sort(np.array(obs_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33e77a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate the Datasets object back from the OGIP files\n",
    "datasets = Datasets()\n",
    "for obs in obs_ids:\n",
    "    file = ogip_path / f\"obs_{obs}.fits.gz\"\n",
    "    datasets.append(SpectrumDatasetOnOff.read(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d07c064",
   "metadata": {},
   "source": [
    "# 2. Get some parameters to use from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f07c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_name = []\n",
    "\n",
    "for obs in obs_ids:\n",
    "    file = ogip_path / f\"obs_{obs}.fits.gz\"\n",
    "    r = Table.read(file, hdu=\"REGION\").meta\n",
    "    \n",
    "    obj_name.append(r[\"OBJECT\"])\n",
    "print(obs_ids)\n",
    "\n",
    "obj_name = np.unique(np.array(obj_name))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ccd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_reco_edges = datasets[0].counts.geom.axes[\"energy\"].edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef84ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy range for spectral fitting the dataset.\n",
    "# One can play with different energy bins to check the different spectral fits\n",
    "e_fit_min = 0.01\n",
    "e_fit_max = 40\n",
    "\n",
    "# Using bins per decade\n",
    "e_fit_bin_p_dec = 5\n",
    "\n",
    "energy_fit_edges = MapAxis.from_energy_bounds(\n",
    "    e_fit_min, e_fit_max, \n",
    "    nbin=e_fit_bin_p_dec, per_decade=True, \n",
    "    unit=\"TeV\"\n",
    ").edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910069e1",
   "metadata": {},
   "source": [
    "# 3. Get Pivot energy to fix the reference energy and define the Spectrum Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pivot (decorrelation) energy for a Power Law model to get the reference energy for Log Parabola model\n",
    "def get_pivot_energy(datasets, e_ref, e_edges, obj_name):\n",
    "    \"\"\"\n",
    "    Using Power Law spectral model with the given reference energy and \n",
    "    get the decorrelation energy of the fit, within the fit energy range, e_edges\n",
    "    \"\"\"\n",
    "    spectral_model = PowerLawSpectralModel(\n",
    "        index=2, amplitude=2e-11 * u.Unit(\"cm-2 s-1 TeV-1\"), reference=e_ref\n",
    "    )\n",
    "    model = SkyModel(spectral_model=spectral_model, name=obj_name)\n",
    "    model_check = model.copy()\n",
    "\n",
    "    # Stacked dataset method\n",
    "    stacked_dataset = Datasets(datasets).stack_reduce()\n",
    "    stacked_dataset.models = model_check\n",
    "\n",
    "    fit_stacked = Fit()\n",
    "    result_stacked = fit_stacked.run(datasets=stacked_dataset)\n",
    "\n",
    "    return model_check.spectral_model.pivot_energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a reference energy close to the expected decorrelation energy\n",
    "ref = get_pivot_energy(datasets, 0.4 * u.TeV, e_reco_edges, obj_name)\n",
    "print(ref.to_value(u.GeV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final spectral model of Log Parabola, to be used for estimating the LC.\n",
    "# One can try different Spectral Models as well.\n",
    "# Be careful in the choice of Spectral Model being used for the 2 examples presented here\n",
    "\n",
    "# Crab\n",
    "spectral_model_lp = LogParabolaSpectralModel(\n",
    "        amplitude = 5e-12 * u.Unit('cm-2 s-1 TeV-1'),\n",
    "        reference = ref,\n",
    "        alpha = 2 * u.Unit(''),\n",
    "        beta = 0.1 * u.Unit('')\n",
    ")\n",
    "model_lp = SkyModel(spectral_model=spectral_model_lp, name=obj_name)\n",
    "\n",
    "#BL Lac\n",
    "spectral_model_lp_bllac = LogParabolaSpectralModel(\n",
    "        amplitude = 3e-8 * u.Unit('cm-2 s-1 TeV-1'),\n",
    "        reference = 0.1 * u.TeV,\n",
    "        alpha = 2 * u.Unit(''),\n",
    "        beta = 0.2 * u.Unit('')\n",
    ")\n",
    "model_lp_bllac = SkyModel(spectral_model=spectral_model_lp_bllac, name=obj_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the appropriate models, as per the selection of the source/dataset\n",
    "params=model_lp.to_dict()['spectral']['parameters']\n",
    "# params=model_lp_bllac.to_dict()['spectral']['parameters']\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f61c2c",
   "metadata": {},
   "source": [
    "# 4. Spectral Fitting\n",
    "One can check for a more comprehensive tutorial on Modelling and Fitting, here are the gammapy tutorials -\n",
    "* https://docs.gammapy.org/0.19/tutorials/api/fitting.html\n",
    "* https://docs.gammapy.org/0.19/tutorials/api/model_management.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa1a454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using stacked analysis method, where we stack together all Datasets into 1 Dataset and add the model afterwards\n",
    "stacked_dataset = Datasets(datasets).stack_reduce()\n",
    "stacked_dataset.models = model_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006acdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model to the dataset\n",
    "fit = Fit()\n",
    "result = fit.run(datasets=stacked_dataset)\n",
    "model_best = model_lp.copy() # creating a copy of the model, to avoid overwriting of the original object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Flux Points after Fitting the model\n",
    "# We do not do too many optimizations here. \n",
    "# If one wants, can try and check the various attributes of the Estimator\n",
    "fpe = FluxPointsEstimator(\n",
    "    energy_edges=energy_fit_edges, \n",
    "    reoptimize = False, # Re-optimizing other free model parameters (not belonging to the source)\n",
    "    source=obj_name,\n",
    "    selection_optional=\"all\" # Estimates asymmetric errors, upper limits and fit statistic profiles\n",
    ")\n",
    "flux_points = fpe.run(datasets=stacked_dataset)\n",
    "\n",
    "flux_points_dataset = FluxPointsDataset(\n",
    "    data=flux_points, models=model_best\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdce50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result\n",
    "# Gammapy bug, which will be fixed in the next release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810aa480",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.to_dict()['spectral']['parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85793b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flux_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a158e5a7",
   "metadata": {},
   "source": [
    "# 5. Check some features of the Flux points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0da937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Flux table\n",
    "# sed_type options are {“likelihood”, “dnde”, “e2dnde”, “flux”, “eflux”} with \"likelihood\" being default\n",
    "# format options are {“gadf-sed”, “lightcurve”, “binned-time-series”, “profile”} with \"gadf-sed\" being default\n",
    "flux_points.to_table(formatted=True, sed_type=\"e2dnde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51652dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Statistic array\n",
    "print(flux_points_dataset.stat_array())\n",
    "\n",
    "# Total statistics sum\n",
    "print(flux_points_dataset.stat_sum(), np.nansum(flux_points_dataset.stat_array()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.parameters.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f55fc7",
   "metadata": {},
   "source": [
    "# 6. Spectral plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if obj_name == 'Crab':\n",
    "    ref_label=\"MAGIC LP (JHEAp 2015)\"\n",
    "else:\n",
    "    ref_label=\"Crab MAGIC LP (JHEAp 2015)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c002cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Setting plot axes limits and other args\n",
    "e_plot_min = 0.01 * u.TeV\n",
    "e_plot_max = 40 * u.TeV\n",
    "\n",
    "ds_kwargs = {\n",
    "    \"sed_type\": \"dnde\",\n",
    "    \"energy_bounds\": [e_plot_min, e_plot_max],\n",
    "    \"yunits\": u.Unit(\"erg-1 cm-2 s-1\"),\n",
    "}\n",
    "sed_kwargs = {\n",
    "    \"sed_type\": \"e2dnde\",\n",
    "    \"energy_bounds\": [e_plot_min, e_plot_max],\n",
    "    \"yunits\": u.Unit(\"erg cm-2 s-1\"),\n",
    "\n",
    "}\n",
    "sed_plot_kwargs = {\n",
    "    \"label\": \"LST-1 data\",\n",
    "}\n",
    "plot_ts_kwargs = {\n",
    "    \"color\": \"darkorange\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008ca2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "ax = flux_points.plot(sed_type=\"e2dnde\", **plot_ts_kwargs)\n",
    "\n",
    "flux_points.plot_ts_profiles(ax=ax, sed_type=\"e2dnde\")\n",
    "\n",
    "plt.grid(which='both')\n",
    "plt.title('TS Profiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc63a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model covariance matrix plot\n",
    "model_best.covariance.plot_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7af0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_sed = plt.figure(figsize=(8,8))\n",
    "\n",
    "gs2 = GridSpec(7, 1)\n",
    "\n",
    "gs2.update(hspace=0.1)\n",
    "args1 = [gs2[:5,:]]\n",
    "args2 = [gs2[5:,:]]\n",
    "\n",
    "fig_gs1 = fig_sed.add_subplot(*args1)\n",
    "fig_gs2 = fig_sed.add_subplot(*args2)\n",
    "\n",
    "FluxPointsDataset(data=flux_points, models=model_best).plot_spectrum(\n",
    "    ax=fig_gs1, \n",
    "    kwargs_fp=sed_plot_kwargs, \n",
    ")\n",
    "\n",
    "create_crab_spectral_model(\"magic_lp\").plot(\n",
    "    ax=fig_gs1, **sed_kwargs, label=ref_label\n",
    ")\n",
    "\n",
    "fig_gs1.legend()\n",
    "fig_gs1.set_xlim(e_plot_min.value, e_plot_max.value)\n",
    "fig_gs1.set_ylim(2e-12, 2e-10)\n",
    "fig_gs1.tick_params(labelbottom=False)\n",
    "\n",
    "fig_gs1.grid(which='both')\n",
    "fig_gs1.set_title('SED')\n",
    "\n",
    "flux_points_dataset.plot_residuals(ax=fig_gs2, method='diff/model')\n",
    "fig_gs2.grid(which='both')\n",
    "fig_gs2.set_xlim(e_plot_min.value, e_plot_max.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b48054",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,7))\n",
    "gs = GridSpec(7, 1)\n",
    "\n",
    "args1 = [gs[:5,:]]\n",
    "args2 = [gs[5:,:]]\n",
    "kwargs_res = {\"method\": \"diff/sqrt(model)\"}\n",
    "\n",
    "fig_gs1 = fig.add_subplot(*args1)\n",
    "fig_gs2 = fig.add_subplot(*args2)\n",
    "\n",
    "stacked_dataset.plot_excess(fig_gs1)\n",
    "fig_gs1.grid(which=\"both\")\n",
    "fig_gs1.set_ylabel(\"Excess\")\n",
    "\n",
    "stacked_dataset.plot_residuals_spectral(fig_gs2, **kwargs_res, region=stacked_dataset.counts.geom.region)\n",
    "fig_gs2.grid(which=\"both\")\n",
    "\n",
    "fig_gs2.set_ylabel(f\"Residuals \\n (data-model)/sqrt(model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57465e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "flux_points.plot(label='Joint flux')\n",
    "create_crab_spectral_model(\"magic_lp\").plot(**ds_kwargs, label=ref_label)\n",
    "plt.grid(which='both')\n",
    "plt.legend()\n",
    "plt.title('Differential spectrum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03c47c",
   "metadata": {},
   "source": [
    "# 7. Save the Flux Points Dataset and Model to separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_points.write(\n",
    "    base_dir + dir_path + f'{obj_name}_dataset_{datasets[0].name}_to_{datasets[-1].name}_flux_pts.fits', \n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# write the model to a dict and then to a file\n",
    "model_dict = model_best.to_dict(full_output='True')\n",
    "\n",
    "f = open(base_dir + dir_path + f'{obj_name}_dataset_{datasets[0].name}_to_{datasets[-1].name}_flux_model_dict.dat', 'wb')\n",
    "\n",
    "pickle.dump(model_dict, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de0138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lst-dev",
   "language": "python",
   "name": "lst-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
