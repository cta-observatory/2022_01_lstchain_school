{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37bffb8b",
   "metadata": {},
   "source": [
    "This is the start \n",
    "For a simple comprehensive tutorial from gammapy, one can follow https://docs.gammapy.org/0.18.2/tutorials/spectrum_analysis.html\n",
    "\n",
    "Here we break the post-DL3 analyses to simple and separate sections to ease the facilitation of all steps - \n",
    "# 1. Reduce DL3 data into Spectrum Dataset objects in OGIP files\n",
    "# 2. Plot LC from the OGIP files\n",
    "# 3. Plot SEDs from the OGIP files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe60fa59",
   "metadata": {},
   "source": [
    "# This example notebook, converts the provided DL3 files into Spectrum Dataset objects and saves the 1D counts spectra and Associated Response Function in OGIP format, as following:\n",
    "\n",
    "## 1. Read the provided DL3 index files\n",
    "## 2. Apply selection filters to the list of DL3 files\n",
    "## 3. Define base geometry for the 1D spectrum\n",
    "## 4. Generate some dataset makers for data reduction\n",
    "## 5. Perform data reduction over all selected observations and compile them to a Dataset\n",
    "## 6. Save the Dataset to OGIP files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e80c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from regions import CircleSkyRegion\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1babec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.data import DataStore\n",
    "\n",
    "from gammapy.maps import Map, MapAxis, WcsNDMap, WcsGeom, RegionGeom\n",
    "from gammapy.data import DataStore\n",
    "\n",
    "from gammapy.datasets import (\n",
    "    Datasets,\n",
    "    SpectrumDataset,\n",
    "    SpectrumDatasetOnOff,\n",
    ")\n",
    "from gammapy.makers import (\n",
    "    SafeMaskMaker,\n",
    "    SpectrumDatasetMaker,\n",
    "    ReflectedRegionsBackgroundMaker,\n",
    ")\n",
    "\n",
    "from gammapy.visualization import plot_spectrum_datasets_off_regions\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord, Angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1308b",
   "metadata": {},
   "source": [
    "# 1. Parameters from user for selection of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6137387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the DL3 files produced for source dependent or independent analyses\n",
    "base_dir = \"../data/DL3/\"\n",
    "dir_path = base_dir + \"Crab_src_indep/\" # \"BLLac_src_dep/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658cbcf5",
   "metadata": {},
   "source": [
    "If the DL3 index files are note present, run the lstchain_create_dl3_index_files for the given DL3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b40ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lstchain_create_dl3_index_files -d $dir_path --overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc4bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_datastore = DataStore.from_dir(dir_path)\n",
    "\n",
    "plot_path = Path(dir_path + 'plots/')\n",
    "ogip_path = Path(dir_path + 'OGIP/')\n",
    "\n",
    "plot_path.mkdir(exist_ok=True)\n",
    "ogip_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f683b5ad",
   "metadata": {},
   "source": [
    "# 2. Selection filters for the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40149928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the object name from the OBS Table, assuming all the DL3 files are of the same single source.\n",
    "# If not, then select a single object, to produce the relevant Spectrum Dataset file\n",
    "\n",
    "obj_name = np.unique(total_datastore.obs_table[\"OBJECT\"])[0]\n",
    "print(\"The source is\", obj_name)\n",
    "\n",
    "max_zen = 30 # in deg for a maximum limit on zenith pointing of observations\n",
    "min_time = 300 # in seconds for minimum livetime of each observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2527c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_obs_list = total_datastore.obs_table[\"OBS_ID\"].data\n",
    "observations_total = total_datastore.get_observations(total_obs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to see the full Obs table, run this cell\n",
    "total_datastore.obs_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b3ba86",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 3. Make selection of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8226c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_wob = [total_datastore.obs_table[\"OBS_MODE\"]=='WOBBLE']\n",
    "\n",
    "d_time = [total_datastore.obs_table[\"LIVETIME\"]>min_time]\n",
    "d_zen = [total_datastore.obs_table[\"ZEN_PNT\"]<max_zen]\n",
    "d_obj = [total_datastore.obs_table[\"OBJECT\"]==obj_name]\n",
    "\n",
    "wob_obs_table = total_datastore.obs_table[d_wob[0]*d_zen[0]*d_obj[0]*d_time[0]]\n",
    "wob_obs_list = total_datastore.obs_table[d_wob[0]*d_zen[0]*d_obj[0]*d_time[0]][\"OBS_ID\"]\n",
    "\n",
    "observations_wob = total_datastore.get_observations(wob_obs_list.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d39c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Wobble observation runs selected are:', wob_obs_list.data)\n",
    "print(f'Total livetime of all observations: {total_datastore.obs_table[\"LIVETIME\"].data.sum()/3600:.3f} hrs')\n",
    "print(f'Total livetime of all selected wobble observations {wob_obs_table[\"LIVETIME\"].data.sum()/3600:.3f} hrs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794b589",
   "metadata": {},
   "source": [
    "# 4. Some small functions to get parameters for constructing the Geom for SpectrumDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f52b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take it as an exercise?\n",
    "def get_theta_cut_for_geom(dir_path):\n",
    "    filename_list = []\n",
    "    for file in os.listdir(dir_path):\n",
    "        if file.startswith('dl3'):\n",
    "            filename_list.append(file)\n",
    "    filename_list = np.sort(filename_list)\n",
    "    \n",
    "    theta_cut = u.Quantity(\n",
    "        Table.read(\n",
    "            dir_path+filename_list[0], \n",
    "            hdu=\"EFFECTIVE AREA\"\n",
    "        ).meta[\"RAD_MAX\"]\n",
    "    )\n",
    "    \n",
    "    return theta_cut, filename_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa584be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_datastore.hdu_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4220a9",
   "metadata": {},
   "source": [
    "# 5. Define Target position and energy ranges for reconstructed events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_position = SkyCoord.from_name(obj_name, frame='icrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb25bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long way to find the theta cut used for creating the IRFs\n",
    "\n",
    "# Select the HDU entry of the first selected wobble observation\n",
    "hdu_t = total_datastore.hdu_table\n",
    "hdu_idx = np.where(hdu_t[\"OBS_ID\"] == wob_obs_list[0])[0][0]\n",
    "\n",
    "hdu_sel = hdu_t[hdu_idx]\n",
    "print(\"Base directory of the HDU index file,\", hdu_sel.meta[\"BASE_DIR\"])\n",
    "print(\"Location of the selected DL3 file, with respect to HDU index file,\", hdu_sel[\"FILE_DIR\"])\n",
    "print(\"File name of the selected observation,\", hdu_sel[\"FILE_NAME\"])\n",
    "\n",
    "file = Path(hdu_sel.meta[\"BASE_DIR\"]) / hdu_sel[\"FILE_DIR\"] / hdu_sel[\"FILE_NAME\"]\n",
    "\n",
    "# Checking the fixed global theta cut value, stored as RAD_MAX metadata in all IRF HDUs\n",
    "theta_cut = Table.read(file, hdu=\"EFFECTIVE AREA\").meta[\"RAD_MAX\"]\n",
    "print(\"Theta cut applied for creating the IRF in the selected DL3 file,\", theta_cut)\n",
    "\n",
    "# Converting the string data into astropy.units\n",
    "on_region_radius = u.Quantity(theta_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f9d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the minimum, maximum energies in TeV units, and number of bins per decade, to create the \n",
    "# required reconstructed and spectral fit energy ranges.\n",
    "\n",
    "e_reco_min = 0.01 * u.TeV\n",
    "e_reco_max = 40 * u.TeV\n",
    "\n",
    "# The following units will be used now to restrict the events in the Spectrum Dataset, only within \n",
    "# the energy ranges, in which we want to perform spectral analysis.\n",
    "e_fit_min = 0.01 * u.TeV\n",
    "e_fit_max = 40 * u.TeV\n",
    "\n",
    "# Using bins per decade\n",
    "e_reco_bin_p_dec = 5\n",
    "\n",
    "# Calculating the bin size in log scale for the given number of bins per decade\n",
    "e_reco_bin = int(\n",
    "    round(\n",
    "        (np.log10(e_reco_max.value) - np.log10(e_reco_min.value)) * e_reco_bin_p_dec + 1, 0\n",
    "    )\n",
    ")\n",
    "\n",
    "e_reco = MapAxis.from_edges(\n",
    "    np.logspace(\n",
    "        np.log10(e_reco_min.value), \n",
    "        np.log10(e_reco_max.value), \n",
    "        e_reco_bin\n",
    "    ), \n",
    "    unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecb339f",
   "metadata": {},
   "source": [
    "# 6. Define the base Map geometries for creating the SpectrumDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac5aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_region = CircleSkyRegion(center=target_position, radius=on_region_radius)\n",
    "\n",
    "# This will create the base geometry in which to bin the events based on their reconstructed positions\n",
    "# One can also vary the different parameters here, to get required plots\n",
    "geom = WcsGeom.create(\n",
    "    skydir=target_position, npix=(100, 100), \n",
    "    binsz=0.05, frame=\"icrs\", axes=[e_reco]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaf3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusion region/source for Crab - RGB J0521+212. \n",
    "# Can include specific close gamma-ray objects with respect to the given source, after looking at catalogs\n",
    "# like http://gamma-sky.net/\n",
    "RGB_region = CircleSkyRegion(\n",
    "    center=SkyCoord(183.604, -8.708, unit=\"deg\", frame=\"galactic\"),\n",
    "    radius=0.5 * u.deg,\n",
    ")\n",
    "\n",
    "exclusion_regions = [RGB_region]\n",
    "exclusion_mask = geom.to_image().region_mask(exclusion_regions, inside=False)\n",
    "\n",
    "exclusion_mask = WcsNDMap(geom.to_image(), exclusion_mask)\n",
    "exclusion_mask.plot()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06651bb8",
   "metadata": {},
   "source": [
    "# 7. Data Reduction chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b8885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some Dataset and Data Reduction Makers\n",
    "dataset_empty = SpectrumDataset.create(\n",
    "    e_reco=e_reco, region=on_region\n",
    ")\n",
    "# When not including a PSF IRF, put the containment_correction as False\n",
    "dataset_maker = SpectrumDatasetMaker(\n",
    "    containment_correction=False, \n",
    "    selection=[\"counts\", \"exposure\", \"edisp\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b14ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following makers can be tuned and played to check the final Dataset to be used.\n",
    "\n",
    "# Select the necessary number and size of the OFF regions, to be chosen by this method\n",
    "bkg_maker = ReflectedRegionsBackgroundMaker(\n",
    "    exclusion_mask=exclusion_mask,\n",
    "    min_distance_input=2 * u.rad, # Minimum distance from input region\n",
    "    max_region_number=10 # Maximum number of OFF regions\n",
    ") \n",
    "# Can also include other parameters, by checking the documentation,\n",
    "# https://docs.gammapy.org/0.18.2/api/gammapy.makers.ReflectedRegionsBackgroundMaker.html#gammapy.makers.ReflectedRegionsBackgroundMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7778cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maker for safe energy range for the events.\n",
    "safe_mask_masker = SafeMaskMaker(\n",
    "    methods=[\"aeff-max\"], \n",
    "    aeff_percent=10\n",
    ")\n",
    "# For other arguments and options, check the documentation,\n",
    "# https://docs.gammapy.org/0.18.2/api/gammapy.makers.SafeMaskMaker.html#gammapy.makers.SafeMaskMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c37d609",
   "metadata": {},
   "source": [
    "# 8. Generate the Spectrum Dataset for all observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b17e0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# The final object will be stored as a Datasets object\n",
    "datasets = Datasets()\n",
    "\n",
    "for obs_id, observation in zip(wob_obs_list, observations_wob):\n",
    "    dataset = dataset_maker.run(\n",
    "        dataset_empty.copy(name=str(obs_id)), \n",
    "        observation\n",
    "    )\n",
    "    print('obs_id:', obs_id)\n",
    "    \n",
    "    dataset_on_off = bkg_maker.run(\n",
    "        dataset=dataset, \n",
    "        observation=observation\n",
    "    )\n",
    "    \n",
    "    # Some energy masks based on maximum reconstructed energy or spectral fit energy range\n",
    "    # This maybe ignored if the events with full energy range are required.\n",
    "    mask_fit = Map.from_geom(\n",
    "        geom = dataset_on_off.counts.geom, \n",
    "        data = dataset_on_off.counts.geom.get_coord()[\"energy\"] < e_reco_max\n",
    "    )\n",
    "    dataset_on_off.counts.geom.energy_mask(\n",
    "        energy_min=e_fit_min, \n",
    "        energy_max=e_fit_max\n",
    "    )\n",
    "    dataset_on_off.mask_fit = mask_fit\n",
    "    \n",
    "    # Add the name of the observed source\n",
    "    dataset_on_off.meta_table[\"SOURCE\"]=obj_name\n",
    "    \n",
    "    # Check the LC and SEDs by applying the safe mask to see the distinction.\n",
    "    #dataset_on_off = safe_mask_masker.run(dataset_on_off, observation)\n",
    "    \n",
    "    datasets.append(dataset_on_off)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b75eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea40a2a",
   "metadata": {},
   "source": [
    "# 9. Some plots with the given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaea147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the OFF regions used for calculation of excess\n",
    "plt.figure(figsize=(8, 5))\n",
    "_, ax, _ = exclusion_mask.plot()\n",
    "on_region.to_pixel(ax.wcs).plot(ax=ax, edgecolor=\"k\")\n",
    "plot_spectrum_datasets_off_regions(ax=ax, datasets=datasets, legend=True)\n",
    "plt.grid()\n",
    "\n",
    "# If need be, redo section 7 and 8, to be sure of the final dataset.\n",
    "# This could be in the case of using source-dependent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For source dependent analysis, check the reconstructed position of all the events, \n",
    "# to be sure on the type of dateset we have\n",
    "for o in observations_wob:\n",
    "    table=o.events.table\n",
    "    plt.plot((table[\"RA\"]*24/360),(table[\"DEC\"]), '.')\n",
    "plt.grid()\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlabel(\"RA (deg)\")\n",
    "plt.ylabel(\"Dec (deg)\")\n",
    "#plt.xlim(22.13,21.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_table = datasets.info_table(cumulative=True)\n",
    "info_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bc210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temporal evolution of excess events and significance value\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(\n",
    "    np.sqrt(info_table[\"livetime\"].to(\"h\")), info_table[\"excess\"], marker=\"o\", ls=\"none\"\n",
    ")\n",
    "plt.plot(info_table[\"livetime\"].to(\"h\")[-1:1], info_table[\"excess\"][-1:1], 'r')\n",
    "plt.xlabel(\"Sqrt Livetime h^(1/2)\")\n",
    "plt.ylabel(\"Excess\")\n",
    "plt.grid()\n",
    "plt.title('Excess vs Square root of Livetime')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(\n",
    "    np.sqrt(info_table[\"livetime\"].to(\"h\")),\n",
    "    info_table[\"sqrt_ts\"],\n",
    "    marker=\"o\",\n",
    "    ls=\"none\",\n",
    ")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Sqrt Livetime h^(1/2)\")\n",
    "plt.ylabel(\"sqrt_ts\")\n",
    "plt.title('Significance vs Square root of Livetime')\n",
    "plt.subplots_adjust(wspace=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9fdb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Plot the counts+excess, exposure and energy migration of each selected dataset\n",
    "plt.figure(figsize=(21, len(datasets)*5.5))\n",
    "j=1\n",
    "hist_kwargs = {\"vmin\":0, \"vmax\":1}\n",
    "\n",
    "for data in datasets:\n",
    "    plt.subplot(len(datasets), 3, j)\n",
    "    data.plot_counts()\n",
    "    data.plot_excess()\n",
    "    plt.grid(which=\"both\")\n",
    "    plt.title(f'Run {data.name} Counts and Excess')\n",
    "    j += 1\n",
    "    \n",
    "    plt.subplot(len(datasets), 3, j)\n",
    "    data.exposure.plot()\n",
    "    plt.grid(which='both')\n",
    "    plt.title(f'Run {data.name} Exposure')\n",
    "    j += 1\n",
    "    \n",
    "    plt.subplot(len(datasets), 3, j)\n",
    "    if data.edisp is not None:\n",
    "        kernel = data.edisp.get_edisp_kernel()\n",
    "        kernel.plot_matrix(add_cbar=True, **hist_kwargs)\n",
    "        plt.title(f'Run {data.name} Energy Dispersion')\n",
    "    j += 1\n",
    "plt.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5f672",
   "metadata": {},
   "source": [
    "# 10. Write all datasets into OGIP files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177b138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Once the latest dependencies are updated, these warnings will go away\n",
    "for d in datasets:\n",
    "    d.to_ogip_files(\n",
    "        outdir=ogip_path, overwrite=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the OGIP files to include the source object name in its headers, to be used for further analysis\n",
    "for obs in wob_obs_list:\n",
    "    file = ogip_path/f\"pha_obs{obs}.fits\"\n",
    "    \n",
    "    d1 = fits.open(file)\n",
    "    d1[\"REGION\"].header[\"OBJECT\"]=obj_name\n",
    "    d1.writeto(file, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lst-dev",
   "language": "python",
   "name": "lst-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
